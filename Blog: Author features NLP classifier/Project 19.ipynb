{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20bc7c83",
   "metadata": {},
   "source": [
    "<font size=\"4\"> <b> • DOMAIN: </b>Digital content management</font>\n",
    "\n",
    "<font size=\"4\"> <b> • CONTEXT: </b>Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles,\n",
    "etc. is written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to create a classifier that predicts multiple features of the author of a given text. We have designed it as a Multi label classification problem.\n",
    "\n",
    "<font size=\"4\"> <b> • DATA DESCRIPTION: </b>Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a blogger id# and the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age but for many,industry and/or sign is marked as unknown.) \n",
    "    \n",
    "All bloggers included in the corpus fall into one of three age groups:\n",
    "    \n",
    "• 8240 \"10s\" blogs (ages 13-17),\n",
    "• 8086 \"20s\" blogs(ages 23-27) and\n",
    "• 2994 \"30s\" blogs (ages 33-47)\n",
    "    \n",
    "For each age group, there is an equal number of male and female bloggers.\n",
    "Each blog in the corpus includes at least 200 occurrences of common English words. All formatting has been stripped with two exceptions.\n",
    "    \n",
    "Individual posts within a single blogger are separated by the date of the following post and links within a post are denoted by the label url\n",
    "link. Link to dataset: https://www.kaggle.com/rtatman/blog-authorship-corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5438c04",
   "metadata": {},
   "source": [
    "<font size=\"4\"> <b> • PROJECT OBJECTIVE: </b>The need is to build a NLP classifier which can use input text parameters to determine the label/s of the blog.\n",
    "\n",
    "<b>Steps and tasks:</b>\n",
    "    \n",
    "1. Import and analyse the data set. \n",
    "2. Perform data pre-processing on the data:\n",
    "    \n",
    ">Data cleansing by removing unwanted characters, spaces, stop words etc. Convert text to lowercase.\n",
    "    \n",
    ">Target/label merger and transformation\n",
    "    \n",
    ">Train and test split\n",
    "  \n",
    ">Vectorisation, etc.\n",
    "    \n",
    "3. Design, train, tune and test the best text classifier\n",
    "    \n",
    "&nbsp;\n",
    "4. Display and explain detail the classification report\n",
    "    \n",
    "&nbsp;\n",
    "5. Print the true vs predicted labels for any 5 entries from the dataset.\n",
    "    \n",
    "<b>Hint: The aim here Is to import the text, process it such a way that it can be taken as an inout to the ML/NN classifiers. Be analytical and experimental here in trying new\n",
    "    approaches to design the best model.</b>\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a3bc9",
   "metadata": {},
   "source": [
    "<font size=\"5\"><p style=\"color:black\"> <b>1. Import and analyse the data set. </p></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66386f1e",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial; font-weight:bold;font-size:1.3em;color:#00b3e5;\">1.1 Importing dataset and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bbba912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484bbceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sathya99\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "929cfb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>I had an interesting conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>Somehow Coca-Cola has a way of su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>If anything, Korea is a country o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>Take a read of this news article ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>I surf the English news sites a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>Ah, the Korean language...it look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>If you click on my profile you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>Last night was pretty fun...mostl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>There is so much that is differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>urlLink    Here it is, the super...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>One thing I love about Seoul (and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>urlLink    Wonderful oh-gyup-sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>18,June,2004</td>\n",
       "      <td>Here is the latest from the Korea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>17,June,2004</td>\n",
       "      <td>Well, I stand corrected, again.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>16,June,2004</td>\n",
       "      <td>So I've been in Vancouver a few d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id gender  age              topic      sign          date  \\\n",
       "0   2059027   male   15            Student       Leo   14,May,2004   \n",
       "1   2059027   male   15            Student       Leo   13,May,2004   \n",
       "2   2059027   male   15            Student       Leo   12,May,2004   \n",
       "3   2059027   male   15            Student       Leo   12,May,2004   \n",
       "4   3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "5   3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "6   3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "7   3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "8   3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "9   3581210   male   33  InvestmentBanking  Aquarius  09,June,2004   \n",
       "10  3581210   male   33  InvestmentBanking  Aquarius  09,June,2004   \n",
       "11  3581210   male   33  InvestmentBanking  Aquarius  09,June,2004   \n",
       "12  3581210   male   33  InvestmentBanking  Aquarius  09,June,2004   \n",
       "13  3581210   male   33  InvestmentBanking  Aquarius  09,June,2004   \n",
       "14  3581210   male   33  InvestmentBanking  Aquarius  09,June,2004   \n",
       "15  3581210   male   33  InvestmentBanking  Aquarius  09,June,2004   \n",
       "16  3581210   male   33  InvestmentBanking  Aquarius  09,June,2004   \n",
       "17  3581210   male   33  InvestmentBanking  Aquarius  18,June,2004   \n",
       "18  3581210   male   33  InvestmentBanking  Aquarius  17,June,2004   \n",
       "19  3581210   male   33  InvestmentBanking  Aquarius  16,June,2004   \n",
       "\n",
       "                                                 text  \n",
       "0              Info has been found (+/- 100 pages,...  \n",
       "1              These are the team members:   Drewe...  \n",
       "2              In het kader van kernfusie op aarde...  \n",
       "3                    testing!!!  testing!!!            \n",
       "4                Thanks to Yahoo!'s Toolbar I can ...  \n",
       "5                I had an interesting conversation...  \n",
       "6                Somehow Coca-Cola has a way of su...  \n",
       "7                If anything, Korea is a country o...  \n",
       "8                Take a read of this news article ...  \n",
       "9                I surf the English news sites a l...  \n",
       "10               Ah, the Korean language...it look...  \n",
       "11               If you click on my profile you'll...  \n",
       "12               Last night was pretty fun...mostl...  \n",
       "13               There is so much that is differen...  \n",
       "14                urlLink    Here it is, the super...  \n",
       "15               One thing I love about Seoul (and...  \n",
       "16                urlLink    Wonderful oh-gyup-sal...  \n",
       "17               Here is the latest from the Korea...  \n",
       "18               Well, I stand corrected, again.  ...  \n",
       "19               So I've been in Vancouver a few d...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset+-+blogtext.csv',nrows=100000)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe16eef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ed73f",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial; font-weight:bold;font-size:1.3em;color:#00b3e5;\">1.2 Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fc9aadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes = df.duplicated()\n",
    "sum(dupes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1621c1a",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial; font-weight:bold;font-size:1.3em;color:#00b3e5;\">1.3 Checking for Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "813ad293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sign</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Total  Percent\n",
       "id          0      0.0\n",
       "gender      0      0.0\n",
       "age         0      0.0\n",
       "topic       0      0.0\n",
       "sign        0      0.0\n",
       "date        0      0.0\n",
       "text        0      0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def missing_check(df):\n",
    "    total = df.isnull().sum().sort_values(ascending=False)   # total number of null values\n",
    "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)  # percentage of values that are null\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])  # putting the above two together\n",
    "    return missing_data # return the dataframe\n",
    "missing_check(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f643ab7",
   "metadata": {},
   "source": [
    "<font size=\"5\"><p style=\"color:black\"> <b> 2. Perform data pre-processing on the data:</p></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58fe94",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial; font-weight:bold;font-size:1.3em;color:#00b3e5;\">2.1 Data cleansing by removing unwanted characters, spaces, stop words etc. Convert text to lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f141663c",
   "metadata": {},
   "source": [
    "**Using Regular expressions to cleanse data to make it suitable for further modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e79240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text']=df['text'].apply(lambda x: re.sub(r'[^A-Za-z]+',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdae701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text']=df['cleaned_text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5777f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text']=df['cleaned_text'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c528caae",
   "metadata": {},
   "source": [
    "**Actual Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "836f3860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual text:\n",
      "\n",
      "              If anything, Korea is a country of extremes.  Everything here seems fad-based.  I think it may come from Korea's history.  It has been invaded a reported 700 times over the years, and each time they got independence I imagine they had to move quickly to get to the next level before the next war or occupation.  Lately (well, not really lately...in 1945) the Japanese Occupation ended.  Then the Korean War occurred from 1950-3.  After that there was turmoil, but in 1961 Park Chung Hee took over as dictator/president.  He had elections, in which everyone was 'encouraged' to vote, but he was still a dictator.  After his assassination in 1979 the next few leaders were basically of the same ilk.  President Park did some amazing things in his time, however.  He took an incredibly backward country and set it on the road to industrialization. Japan had stripped Korea of its resources, people and even its language and culture (many buildings and palaces were razed and Japanese was the official language here from 1910-1945) but President Park was determined to change that.  He orchestrated the 'Han River Miracle' (the Han River, or Hangang 한강 is the main river in Seoul/Korea) and Korea made terrific strides, if at the expense of some civil liberties.  Fastforward to the present, and my point, and we see that Korea is the world's #1 wired nation.  More than Canada, Finland and way beyond the U.S.A.  There was a craze to have PC방s (PC bangs or rooms) EVERYWHERE in the country.  As well, instead of PlayStation-like games where players go against the computer or one or two people, Korean gamers (always the communal types) play online games with hundreds or thousands of others. in typical Korean fashion, gamers who left their seat for a second could not pause their game...in fact, they may be eliminated.  So PCbang owners sold drinks, ramen nooodles and other junk to their clientele.  It was just a matter of time before someone died, as related in  urlLink this article .  Yes, someone died from being on the PC.  People thought he was just sleeping (imagine how long he was there before they really checked him out) but, alas, he was the first known casulty of the Net in Korea, maybe the world.  Korea, built on extremes, both good and bad.         \n"
     ]
    }
   ],
   "source": [
    "print(\"Actual text:\\n\\n\", df['text'][7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d4c971",
   "metadata": {},
   "source": [
    "**Text after Data wrangling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fabe2ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text after Data wrangling:\n",
      "\n",
      " if anything korea is a country of extremes everything here seems fad based i think it may come from korea s history it has been invaded a reported times over the years and each time they got independence i imagine they had to move quickly to get to the next level before the next war or occupation lately well not really lately in the japanese occupation ended then the korean war occurred from after that there was turmoil but in park chung hee took over as dictator president he had elections in which everyone was encouraged to vote but he was still a dictator after his assassination in the next few leaders were basically of the same ilk president park did some amazing things in his time however he took an incredibly backward country and set it on the road to industrialization japan had stripped korea of its resources people and even its language and culture many buildings and palaces were razed and japanese was the official language here from but president park was determined to change that he orchestrated the han river miracle the han river or hangang is the main river in seoul korea and korea made terrific strides if at the expense of some civil liberties fastforward to the present and my point and we see that korea is the world s wired nation more than canada finland and way beyond the u s a there was a craze to have pc s pc bangs or rooms everywhere in the country as well instead of playstation like games where players go against the computer or one or two people korean gamers always the communal types play online games with hundreds or thousands of others in typical korean fashion gamers who left their seat for a second could not pause their game in fact they may be eliminated so pcbang owners sold drinks ramen nooodles and other junk to their clientele it was just a matter of time before someone died as related in urllink this article yes someone died from being on the pc people thought he was just sleeping imagine how long he was there before they really checked him out but alas he was the first known casulty of the net in korea maybe the world korea built on extremes both good and bad\n"
     ]
    }
   ],
   "source": [
    "print(\"Text after Data wrangling:\\n\\n\", df['cleaned_text'][7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d753886",
   "metadata": {},
   "source": [
    "**Remove all stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea07c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "136427fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text']=df['cleaned_text'].apply(lambda x: ' '.join([words for words in x.split() if words not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "351c5987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anything korea country extremes everything seems fad based think may come korea history invaded reported times years time got independence imagine move quickly get next level next war occupation lately well really lately japanese occupation ended korean war occurred turmoil park chung hee took dictator president elections everyone encouraged vote still dictator assassination next leaders basically ilk president park amazing things time however took incredibly backward country set road industrialization japan stripped korea resources people even language culture many buildings palaces razed japanese official language president park determined change orchestrated han river miracle han river hangang main river seoul korea korea made terrific strides expense civil liberties fastforward present point see korea world wired nation canada finland way beyond u craze pc pc bangs rooms everywhere country well instead playstation like games players go computer one two people korean gamers always communal types play online games hundreds thousands others typical korean fashion gamers left seat second could pause game fact may eliminated pcbang owners sold drinks ramen nooodles junk clientele matter time someone died related urllink article yes someone died pc people thought sleeping imagine long really checked alas first known casulty net korea maybe world korea built extremes good bad'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text'][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704be17b",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial; font-weight:bold;font-size:1.3em;color:#00b3e5;\">2.2 Target/label merger and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69d1ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels']=df.apply(lambda col: [col['gender'],str(col['age']),col['topic'],col['sign']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62025a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>team members drewes van der laag urllink mail ...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \\\n",
       "0             Info has been found (+/- 100 pages,...   \n",
       "1             These are the team members:   Drewe...   \n",
       "2             In het kader van kernfusie op aarde...   \n",
       "3                   testing!!!  testing!!!             \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  info found pages mb pdf files wait untill team...   \n",
       "1  team members drewes van der laag urllink mail ...   \n",
       "2  het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                    testing testing   \n",
       "4  thanks yahoo toolbar capture urls popups means...   \n",
       "\n",
       "                                    labels  \n",
       "0                 [male, 15, Student, Leo]  \n",
       "1                 [male, 15, Student, Leo]  \n",
       "2                 [male, 15, Student, Leo]  \n",
       "3                 [male, 15, Student, Leo]  \n",
       "4  [male, 33, InvestmentBanking, Aquarius]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e064a380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>team members drewes van der laag urllink mail ...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>Student</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>THE HINDU - 125 YEARS             ...</td>\n",
       "      <td>hindu years great see special edition hindu co...</td>\n",
       "      <td>[male, 27, Student, Virgo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>Student</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>DILBERT &amp; IIT-ans                 ...</td>\n",
       "      <td>dilbert iit ans global iit brand finds space u...</td>\n",
       "      <td>[male, 27, Student, Virgo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>Student</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>Case Study : How HP won $3 billion...</td>\n",
       "      <td>case study hp billion p g outsourcing deal bea...</td>\n",
       "      <td>[male, 27, Student, Virgo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>Student</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>Championing Chennai               ...</td>\n",
       "      <td>championing chennai bangalore iim hyderabad ho...</td>\n",
       "      <td>[male, 27, Student, Virgo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>Student</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>WEEKEND                         It...</td>\n",
       "      <td>weekend turned rather interesting different we...</td>\n",
       "      <td>[male, 27, Student, Virgo]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age              topic      sign  \\\n",
       "0       male   15            Student       Leo   \n",
       "1       male   15            Student       Leo   \n",
       "2       male   15            Student       Leo   \n",
       "3       male   15            Student       Leo   \n",
       "4       male   33  InvestmentBanking  Aquarius   \n",
       "...      ...  ...                ...       ...   \n",
       "99995   male   27            Student     Virgo   \n",
       "99996   male   27            Student     Virgo   \n",
       "99997   male   27            Student     Virgo   \n",
       "99998   male   27            Student     Virgo   \n",
       "99999   male   27            Student     Virgo   \n",
       "\n",
       "                                                    text  \\\n",
       "0                 Info has been found (+/- 100 pages,...   \n",
       "1                 These are the team members:   Drewe...   \n",
       "2                 In het kader van kernfusie op aarde...   \n",
       "3                       testing!!!  testing!!!             \n",
       "4                   Thanks to Yahoo!'s Toolbar I can ...   \n",
       "...                                                  ...   \n",
       "99995              THE HINDU - 125 YEARS             ...   \n",
       "99996              DILBERT & IIT-ans                 ...   \n",
       "99997              Case Study : How HP won $3 billion...   \n",
       "99998              Championing Chennai               ...   \n",
       "99999              WEEKEND                         It...   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "0      info found pages mb pdf files wait untill team...   \n",
       "1      team members drewes van der laag urllink mail ...   \n",
       "2      het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                        testing testing   \n",
       "4      thanks yahoo toolbar capture urls popups means...   \n",
       "...                                                  ...   \n",
       "99995  hindu years great see special edition hindu co...   \n",
       "99996  dilbert iit ans global iit brand finds space u...   \n",
       "99997  case study hp billion p g outsourcing deal bea...   \n",
       "99998  championing chennai bangalore iim hyderabad ho...   \n",
       "99999  weekend turned rather interesting different we...   \n",
       "\n",
       "                                        labels  \n",
       "0                     [male, 15, Student, Leo]  \n",
       "1                     [male, 15, Student, Leo]  \n",
       "2                     [male, 15, Student, Leo]  \n",
       "3                     [male, 15, Student, Leo]  \n",
       "4      [male, 33, InvestmentBanking, Aquarius]  \n",
       "...                                        ...  \n",
       "99995               [male, 27, Student, Virgo]  \n",
       "99996               [male, 27, Student, Virgo]  \n",
       "99997               [male, 27, Student, Virgo]  \n",
       "99998               [male, 27, Student, Virgo]  \n",
       "99999               [male, 27, Student, Virgo]  \n",
       "\n",
       "[100000 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(['id','date'],axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0424eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1[['cleaned_text','labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d21e23d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team members drewes van der laag urllink mail ...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testing testing</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>hindu years great see special edition hindu co...</td>\n",
       "      <td>[male, 27, Student, Virgo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>dilbert iit ans global iit brand finds space u...</td>\n",
       "      <td>[male, 27, Student, Virgo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>case study hp billion p g outsourcing deal bea...</td>\n",
       "      <td>[male, 27, Student, Virgo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>championing chennai bangalore iim hyderabad ho...</td>\n",
       "      <td>[male, 27, Student, Virgo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>weekend turned rather interesting different we...</td>\n",
       "      <td>[male, 27, Student, Virgo]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            cleaned_text  \\\n",
       "0      info found pages mb pdf files wait untill team...   \n",
       "1      team members drewes van der laag urllink mail ...   \n",
       "2      het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                        testing testing   \n",
       "4      thanks yahoo toolbar capture urls popups means...   \n",
       "...                                                  ...   \n",
       "99995  hindu years great see special edition hindu co...   \n",
       "99996  dilbert iit ans global iit brand finds space u...   \n",
       "99997  case study hp billion p g outsourcing deal bea...   \n",
       "99998  championing chennai bangalore iim hyderabad ho...   \n",
       "99999  weekend turned rather interesting different we...   \n",
       "\n",
       "                                        labels  \n",
       "0                     [male, 15, Student, Leo]  \n",
       "1                     [male, 15, Student, Leo]  \n",
       "2                     [male, 15, Student, Leo]  \n",
       "3                     [male, 15, Student, Leo]  \n",
       "4      [male, 33, InvestmentBanking, Aquarius]  \n",
       "...                                        ...  \n",
       "99995               [male, 27, Student, Virgo]  \n",
       "99996               [male, 27, Student, Virgo]  \n",
       "99997               [male, 27, Student, Virgo]  \n",
       "99998               [male, 27, Student, Virgo]  \n",
       "99999               [male, 27, Student, Virgo]  \n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405fd938",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial; font-weight:bold;font-size:1.3em;color:#00b3e5;\">2.3 Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6f8a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df2['cleaned_text']\n",
    "y=df2['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16a32d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3, train_size = 0.7, random_state =12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54189374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000,), (30000,), (70000,), (30000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2771394",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial; font-weight:bold;font-size:1.3em;color:#00b3e5;\">2.4 Vectorisation, MultiLabel Binarizer etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1238dc87",
   "metadata": {},
   "source": [
    "**Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b047011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04a847e",
   "metadata": {},
   "source": [
    "**Total number of words in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32710f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3738224"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(x_train)\n",
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31a59d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aa aa',\n",
       " 'aa alexisonfire',\n",
       " 'aa amazing',\n",
       " 'aa anyway',\n",
       " 'aa back',\n",
       " 'aa batteries',\n",
       " 'aa beautiful',\n",
       " 'aa brown',\n",
       " 'aa button',\n",
       " 'aa candle',\n",
       " 'aa charge',\n",
       " 'aa class',\n",
       " 'aa coming',\n",
       " 'aa compared',\n",
       " 'aa damn',\n",
       " 'aa done',\n",
       " 'aa eating',\n",
       " 'aa ended',\n",
       " 'aa enough',\n",
       " 'aa eriol',\n",
       " 'aa fc',\n",
       " 'aa flights',\n",
       " 'aa forms',\n",
       " 'aa gai',\n",
       " 'aa gaye',\n",
       " 'aa going',\n",
       " 'aa great',\n",
       " 'aa grins',\n",
       " 'aa haha',\n",
       " 'aa hey',\n",
       " 'aa htm',\n",
       " 'aa hyper',\n",
       " 'aa jaeyin',\n",
       " 'aa join',\n",
       " 'aa keeps',\n",
       " 'aa kenyan',\n",
       " 'aa kk',\n",
       " 'aa knows',\n",
       " 'aa lets',\n",
       " 'aa like',\n",
       " 'aa lizzy',\n",
       " 'aa lovedocmartens',\n",
       " 'aa man',\n",
       " 'aa meeting',\n",
       " 'aa meetings',\n",
       " 'aa milne',\n",
       " 'aa months',\n",
       " 'aa motoring',\n",
       " 'aa motw',\n",
       " 'aa much',\n",
       " 'aa nbsp',\n",
       " 'aa ncaa',\n",
       " 'aa need',\n",
       " 'aa nothing',\n",
       " 'aa one',\n",
       " 'aa page',\n",
       " 'aa people',\n",
       " 'aa players',\n",
       " 'aa pona',\n",
       " 'aa process',\n",
       " 'aa raha',\n",
       " 'aa restaurant',\n",
       " 'aa right',\n",
       " 'aa screed',\n",
       " 'aa sd',\n",
       " 'aa snake',\n",
       " 'aa soon',\n",
       " 'aa southpaw',\n",
       " 'aa species',\n",
       " 'aa st',\n",
       " 'aa sudden',\n",
       " 'aa suppose',\n",
       " 'aa tax',\n",
       " 'aa think',\n",
       " 'aa times',\n",
       " 'aa ting',\n",
       " 'aa tobey',\n",
       " 'aa yeah',\n",
       " 'aa yes',\n",
       " 'aa zz',\n",
       " 'aaa',\n",
       " 'aaa aa',\n",
       " 'aaa adi',\n",
       " 'aaa andy',\n",
       " 'aaa asked',\n",
       " 'aaa assistance',\n",
       " 'aaa battery',\n",
       " 'aaa better',\n",
       " 'aaa called',\n",
       " 'aaa candidate',\n",
       " 'aaa car',\n",
       " 'aaa choir',\n",
       " 'aaa choirs',\n",
       " 'aaa clears',\n",
       " 'aaa come',\n",
       " 'aaa compares',\n",
       " 'aaa could',\n",
       " 'aaa discount',\n",
       " 'aaa fashion',\n",
       " 'aaa get',\n",
       " 'aaa gold',\n",
       " 'aaa html',\n",
       " 'aaa instead',\n",
       " 'aaa jellyfish',\n",
       " 'aaa joe',\n",
       " 'aaa looks',\n",
       " 'aaa make',\n",
       " 'aaa members',\n",
       " 'aaa membership',\n",
       " 'aaa mixed',\n",
       " 'aaa morning',\n",
       " 'aaa never',\n",
       " 'aaa nyeh',\n",
       " 'aaa offers',\n",
       " 'aaa office',\n",
       " 'aaa outfielder',\n",
       " 'aaa pawtucket',\n",
       " 'aaa per',\n",
       " 'aaa rated',\n",
       " 'aaa scene',\n",
       " 'aaa show',\n",
       " 'aaa stars',\n",
       " 'aaa take',\n",
       " 'aaa team',\n",
       " 'aaa thing',\n",
       " 'aaa travel',\n",
       " 'aaa university',\n",
       " 'aaa zhinesade',\n",
       " 'aaaa',\n",
       " 'aaaa jet',\n",
       " 'aaaa veerrrrryyy',\n",
       " 'aaaaa',\n",
       " 'aaaaa look',\n",
       " 'aaaaa maganda',\n",
       " 'aaaaaa',\n",
       " 'aaaaaa zhinesade',\n",
       " 'aaaaaaa',\n",
       " 'aaaaaaa love',\n",
       " 'aaaaaaaa',\n",
       " 'aaaaaaaa different',\n",
       " 'aaaaaaaa waiting',\n",
       " 'aaaaaaaa zhinesade',\n",
       " 'aaaaaaaaa',\n",
       " 'aaaaaaaaa going',\n",
       " 'aaaaaaaaa makes',\n",
       " 'aaaaaaaaa remembered',\n",
       " 'aaaaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaa nbsp',\n",
       " 'aaaaaaaaaaaaaaa people',\n",
       " 'aaaaaaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa nope',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa pre',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa perfect',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaarrrrrrrrrrggggggggh',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaahhhhhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaargh',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaargh brother',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaah',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaah awhile',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh okay',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaah',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaah hate',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaghhhhhhhhh',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaghhhhhhhhh huh',\n",
       " 'aaaaaaaaaaaaaaaaaaaaahhhhhhhhhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaaaaaaaaaaaaaahhhhhhhhhhhhhhhhhhhhh hears',\n",
       " 'aaaaaaaaaaaaaaaaaaaarrrrrrrrrrgggggggggghh',\n",
       " 'aaaaaaaaaaaaaaaaaaaarrrrrrrrrrgggggggggghh hhhhhhhhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaaaaaaaaaaaah',\n",
       " 'aaaaaaaaaaaaaaaaaahahhahahahahahhahahahahahahha',\n",
       " 'aaaaaaaaaaaaaaaaaahahhahahahahahhahahahahahahha like',\n",
       " 'aaaaaaaaaaaaaaahhhhhhhhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaaaaaaaahhhhhhhhhhhhhhhhhhhh awful',\n",
       " 'aaaaaaaaaaaaaaarrrrrrrrggggggggggggggghhhhhhhhhhhhh',\n",
       " 'aaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuugggggggggggggggg',\n",
       " 'aaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuugggggggggggggggg back',\n",
       " 'aaaaaaaaaaaaaah',\n",
       " 'aaaaaaaaaaaaaah quote',\n",
       " 'aaaaaaaaaaaaaahhhhhh',\n",
       " 'aaaaaaaaaaaaaahhhhhh part',\n",
       " 'aaaaaaaaaaaaaahhhhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaaaaaaahhhhhhhhhhhhhhhh massive',\n",
       " 'aaaaaaaaaaaaaaw',\n",
       " 'aaaaaaaaaaaaaaw got',\n",
       " 'aaaaaaaaaaaaah',\n",
       " 'aaaaaaaaaaaaah wait',\n",
       " 'aaaaaaaaaaaah',\n",
       " 'aaaaaaaaaaaah bloody',\n",
       " 'aaaaaaaaaaaahhhhhhhhh',\n",
       " 'aaaaaaaaaaaahhhhhhhhh still',\n",
       " 'aaaaaaaaaaah',\n",
       " 'aaaaaaaaaaah drove',\n",
       " 'aaaaaaaaaaah hahha',\n",
       " 'aaaaaaaaaaahhhhhhhhh',\n",
       " 'aaaaaaaaaaahhhhhhhhh know',\n",
       " 'aaaaaaaaaaahhhhhhhhhh',\n",
       " 'aaaaaaaaaaahhhhhhhhhh confused',\n",
       " 'aaaaaaaaaaahhhhhhhhhhhh',\n",
       " 'aaaaaaaaaaand',\n",
       " 'aaaaaaaaaaand done',\n",
       " 'aaaaaaaaaaarrrrrrrrrrrgggggghhhh',\n",
       " 'aaaaaaaaaaarrrrrrrrrrrgggggghhhh work',\n",
       " 'aaaaaaaaaaauuugh',\n",
       " 'aaaaaaaaaaauuugh least',\n",
       " 'aaaaaaaaaaawwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww',\n",
       " 'aaaaaaaaaaawwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww sianz',\n",
       " 'aaaaaaaaaah',\n",
       " 'aaaaaaaaaahhhh',\n",
       " 'aaaaaaaaaahhhh andtakeyourfish',\n",
       " 'aaaaaaaaaahhhhhhhhhh',\n",
       " 'aaaaaaaaaahhhhhhhhhhhhh',\n",
       " 'aaaaaaaaaahhhhhhhhhhhhh say',\n",
       " 'aaaaaaaaaahhhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaaahhhhhhhhhhhhhhh yeeeeeeesssssssss',\n",
       " 'aaaaaaaaaarrrrrrgggggggggghhhhhhh',\n",
       " 'aaaaaaaaaarrrrrrgggggggggghhhhhhh icing',\n",
       " 'aaaaaaaaaarrrrrrrrrrrrgggh',\n",
       " 'aaaaaaaaaarrrrrrrrrrrrgggh ahem',\n",
       " 'aaaaaaaaaarrrrrrrrrrrrrggggggggggggggghhhhhhhhhh',\n",
       " 'aaaaaaaaaarrrrrrrrrrrrrggggggggggggggghhhhhhhhhh fffffaaaaaaaaaaaarrrrrrrrrrrkkkkkkkkkkkkkkkkk',\n",
       " 'aaaaaaaaagh',\n",
       " 'aaaaaaaaagh really',\n",
       " 'aaaaaaaaah',\n",
       " 'aaaaaaaaah honey',\n",
       " 'aaaaaaaaah poor',\n",
       " 'aaaaaaaaahhhhh',\n",
       " 'aaaaaaaaahhhhh wait',\n",
       " 'aaaaaaaaahhhhhh',\n",
       " 'aaaaaaaaahhhhhh relief',\n",
       " 'aaaaaaaaahhhhhhh',\n",
       " 'aaaaaaaaahhhhhhh hahaha',\n",
       " 'aaaaaaaaahhhhhhhh',\n",
       " 'aaaaaaaaahhhhhhhh rather',\n",
       " 'aaaaaaaaahhhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaahhhhhhhhhhhhhhh dae',\n",
       " 'aaaaaaaaahhhhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaahhhhhhhhhhhhhhhh fuck',\n",
       " 'aaaaaaaaallllll',\n",
       " 'aaaaaaaaallllll alone',\n",
       " 'aaaaaaaaanyway',\n",
       " 'aaaaaaaaanyway life',\n",
       " 'aaaaaaaaarrrrrrrrrrrrrrrrrrrrgggggggggggggggggh',\n",
       " 'aaaaaaaaarrrrrrrrrrrrrrrrrrrrgggggggggggggggggh well',\n",
       " 'aaaaaaaagh',\n",
       " 'aaaaaaaagh makes',\n",
       " 'aaaaaaaah',\n",
       " 'aaaaaaaah may',\n",
       " 'aaaaaaaah waitaminute',\n",
       " 'aaaaaaaahhhh',\n",
       " 'aaaaaaaahhhh aaaaaaaahhhh',\n",
       " 'aaaaaaaahhhh aaaaahhhhh',\n",
       " 'aaaaaaaahhhhh',\n",
       " 'aaaaaaaahhhhh looked',\n",
       " 'aaaaaaaahhhhh ready',\n",
       " 'aaaaaaaahhhhh stupid',\n",
       " 'aaaaaaaahhhhhhhhhhhhhhh',\n",
       " 'aaaaaaaahhhhhhhhhhhhhhh ayaw',\n",
       " 'aaaaaaaarggghh',\n",
       " 'aaaaaaaarggghh panic',\n",
       " 'aaaaaaaarrrgh',\n",
       " 'aaaaaaaarrrgh ready',\n",
       " 'aaaaaaaarrrrrrrrrgggghhhhhhhhhhhh',\n",
       " 'aaaaaaaarrrrrrrrrgggghhhhhhhhhhhh name',\n",
       " 'aaaaaaaauuuuuuggggggghhhhhhhh',\n",
       " 'aaaaaaaggghhhhh',\n",
       " 'aaaaaaaggghhhhh feels',\n",
       " 'aaaaaaahh',\n",
       " 'aaaaaaahh days',\n",
       " 'aaaaaaahhhhh',\n",
       " 'aaaaaaahhhhh aint',\n",
       " 'aaaaaaahhhhh oh',\n",
       " 'aaaaaaahhhhhh',\n",
       " 'aaaaaaahhhhhh dorable',\n",
       " 'aaaaaaahhhhhhhhhh',\n",
       " 'aaaaaaahhhhhhhhhh believe',\n",
       " 'aaaaaaahhhhhhhhhhhhrrggh',\n",
       " 'aaaaaaahhhhhhhhhhhhrrggh got',\n",
       " 'aaaaaaand',\n",
       " 'aaaaaaand friday',\n",
       " 'aaaaaaand good',\n",
       " 'aaaaaaarrrrrgggg',\n",
       " 'aaaaaaarrrrrgggg really',\n",
       " 'aaaaaaawwww',\n",
       " 'aaaaaaawwww missed',\n",
       " 'aaaaaack',\n",
       " 'aaaaaack ok',\n",
       " 'aaaaaaghhhhh',\n",
       " 'aaaaaah',\n",
       " 'aaaaaah ow',\n",
       " 'aaaaaah said',\n",
       " 'aaaaaah takers',\n",
       " 'aaaaaahahahahhahaha',\n",
       " 'aaaaaahhh',\n",
       " 'aaaaaahhh customer',\n",
       " 'aaaaaahhh random',\n",
       " 'aaaaaahhhhh',\n",
       " 'aaaaaahhhhh biggest',\n",
       " 'aaaaaahhhhh parents',\n",
       " 'aaaaaahhhhhhh',\n",
       " 'aaaaaahhhhhhh yyyyyyaaaaaa',\n",
       " 'aaaaaahhhhhhhh',\n",
       " 'aaaaaahhhhhhhh well',\n",
       " 'aaaaaalllll',\n",
       " 'aaaaaalllll way',\n",
       " 'aaaaaand',\n",
       " 'aaaaaand back',\n",
       " 'aaaaaannd',\n",
       " 'aaaaaannd see',\n",
       " 'aaaaaanyway',\n",
       " 'aaaaaanyway bad',\n",
       " 'aaaaaargh',\n",
       " 'aaaaaargh god',\n",
       " 'aaaaaarrrrrrgggggggghhhhhhhhh',\n",
       " 'aaaaaaw',\n",
       " 'aaaaaaw guys',\n",
       " 'aaaaaawwwwww',\n",
       " 'aaaaaawwwwww gets',\n",
       " 'aaaaack',\n",
       " 'aaaaafter',\n",
       " 'aaaaafter alll',\n",
       " 'aaaaaggggggghhhhh',\n",
       " 'aaaaaggggggghhhhh iiiiitttttccccchhhhhh',\n",
       " 'aaaaah',\n",
       " 'aaaaah ever',\n",
       " 'aaaaah great',\n",
       " 'aaaaah memories',\n",
       " 'aaaaah sephora',\n",
       " 'aaaaah smell',\n",
       " 'aaaaahhh',\n",
       " 'aaaaahhh went',\n",
       " 'aaaaahhhh',\n",
       " 'aaaaahhhh anyways',\n",
       " 'aaaaahhhh heath',\n",
       " 'aaaaahhhhh',\n",
       " 'aaaaahhhhh lurker',\n",
       " 'aaaaahhhhh never',\n",
       " 'aaaaahhhhh spysweeper',\n",
       " 'aaaaahhhhhh',\n",
       " 'aaaaahhhhhh everything',\n",
       " 'aaaaahhhhhh well',\n",
       " 'aaaaahhhhhhh',\n",
       " 'aaaaahhhhhhh lurker',\n",
       " 'aaaaahhhhhhhhh',\n",
       " 'aaaaahhhhhhhhh today',\n",
       " 'aaaaaing',\n",
       " 'aaaaaing coming',\n",
       " 'aaaaaleluia',\n",
       " 'aaaaaleluia happy',\n",
       " 'aaaaalllll',\n",
       " 'aaaaalllll bout',\n",
       " 'aaaaam',\n",
       " 'aaaaam whenever',\n",
       " 'aaaaammmmmmmmmmmmmm',\n",
       " 'aaaaammmmmmmmmmmmmm uuuuupppppppssssssssseeeeeesssssssssssssssssseeeeeeedddddddddd',\n",
       " 'aaaaand',\n",
       " 'aaaaand got',\n",
       " 'aaaaand looked',\n",
       " 'aaaaand people',\n",
       " 'aaaaano',\n",
       " 'aaaaano stupid',\n",
       " 'aaaaanyhooooo',\n",
       " 'aaaaanyhooooo dont',\n",
       " 'aaaaanyway',\n",
       " 'aaaaanyway decided',\n",
       " 'aaaaanyway jumped',\n",
       " 'aaaaanyway rant',\n",
       " 'aaaaanyway school',\n",
       " 'aaaaarggggghhhhhhhh',\n",
       " 'aaaaarggggghhhhhhhh angry',\n",
       " 'aaaaargh',\n",
       " 'aaaaargh fucking',\n",
       " 'aaaaargh give',\n",
       " 'aaaaargh sploooosh',\n",
       " 'aaaaarghhhhh',\n",
       " 'aaaaarghhhhh man',\n",
       " 'aaaaarrrgggghhhh',\n",
       " 'aaaaarrrgggghhhh finally',\n",
       " 'aaaaarrrrggghhhh',\n",
       " 'aaaaarrrrggghhhh excerpt',\n",
       " 'aaaaarrrrrrggggghhhhhhhhhhhh',\n",
       " 'aaaaarrrrrrggggghhhhhhhhhhhh ok',\n",
       " 'aaaaasmith',\n",
       " 'aaaaasmith great',\n",
       " 'aaaaawwwwwwwww',\n",
       " 'aaaaawwwwwwwww thanks',\n",
       " 'aaaaccchoooo',\n",
       " 'aaaaccchoooo hey',\n",
       " 'aaaack',\n",
       " 'aaaack angry',\n",
       " 'aaaack wanna',\n",
       " 'aaaages',\n",
       " 'aaaages fairly',\n",
       " 'aaaagh',\n",
       " 'aaaagh easily',\n",
       " 'aaaah',\n",
       " 'aaaah effect',\n",
       " 'aaaah excited',\n",
       " 'aaaah futching',\n",
       " 'aaaah havingthe',\n",
       " 'aaaah idle',\n",
       " 'aaaah im',\n",
       " 'aaaah salamat',\n",
       " 'aaaah say',\n",
       " 'aaaah thing',\n",
       " 'aaaah wisdom',\n",
       " 'aaaahahahahahahahahahaha',\n",
       " 'aaaahahahahahahahahahaha someone',\n",
       " 'aaaahh',\n",
       " 'aaaahhh',\n",
       " 'aaaahhh ben',\n",
       " 'aaaahhh creo',\n",
       " 'aaaahhh loved',\n",
       " 'aaaahhhhh',\n",
       " 'aaaahhhhh eyes',\n",
       " 'aaaahing',\n",
       " 'aaaahing possibly',\n",
       " 'aaaall',\n",
       " 'aaaall shared',\n",
       " 'aaaand',\n",
       " 'aaaand go',\n",
       " 'aaaand going',\n",
       " 'aaaand looked',\n",
       " 'aaaand stop',\n",
       " 'aaaannnd',\n",
       " 'aaaannnd quiz',\n",
       " 'aaaannnnddd',\n",
       " 'aaaannnnddd ooooooooonnnnnnnnnn',\n",
       " 'aaaanyways',\n",
       " 'aaaanyways horrible',\n",
       " 'aaaarg',\n",
       " 'aaaarg vowing',\n",
       " 'aaaarggggggghhhhhhhh',\n",
       " 'aaaarggghhh',\n",
       " 'aaaarggghhh thinking',\n",
       " 'aaaarggghhhh',\n",
       " 'aaaarggghhhh saw',\n",
       " 'aaaargh',\n",
       " 'aaaargh much',\n",
       " 'aaaarghh',\n",
       " 'aaaarghh one',\n",
       " 'aaaarrgghhh',\n",
       " 'aaaarrgghhh starting',\n",
       " 'aaaarrrggg',\n",
       " 'aaaarrrggg story',\n",
       " 'aaaarrrgggghhhh',\n",
       " 'aaaarrrgggghhhh hayley',\n",
       " 'aaaarrrgghhhh',\n",
       " 'aaaarrrgghhhh slightly',\n",
       " 'aaaarrrgh',\n",
       " 'aaaarrrgh sweet',\n",
       " 'aaaarrrrggggghhhhhh',\n",
       " 'aaaarrrrggggghhhhhh cant',\n",
       " 'aaaarrrrrgggg',\n",
       " 'aaaarrrrrgggg breathes',\n",
       " 'aaaawww',\n",
       " 'aaaawww wants',\n",
       " 'aaaccckkkk',\n",
       " 'aaaccckkkk bad',\n",
       " 'aaages',\n",
       " 'aaages concerts',\n",
       " 'aaages get',\n",
       " 'aaagh',\n",
       " 'aaagh ok',\n",
       " 'aaagh pero',\n",
       " 'aaah',\n",
       " 'aaah administrative',\n",
       " 'aaah another',\n",
       " 'aaah anyway',\n",
       " 'aaah biology',\n",
       " 'aaah cute',\n",
       " 'aaah decisions',\n",
       " 'aaah dont',\n",
       " 'aaah eat',\n",
       " 'aaah forgeten',\n",
       " 'aaah hafta',\n",
       " 'aaah heheh',\n",
       " 'aaah okok',\n",
       " 'aaah really',\n",
       " 'aaah remember',\n",
       " 'aaah uhhmm',\n",
       " 'aaah urllink',\n",
       " 'aaah wad',\n",
       " 'aaahh',\n",
       " 'aaahh damn',\n",
       " 'aaahh michael',\n",
       " 'aaahh nice',\n",
       " 'aaahh one',\n",
       " 'aaahhh',\n",
       " 'aaahhh cryptic',\n",
       " 'aaahhh didnt',\n",
       " 'aaahhh fix',\n",
       " 'aaahhh get',\n",
       " 'aaahhh mishwa',\n",
       " 'aaahhh mr',\n",
       " 'aaahhh oh',\n",
       " 'aaahhh refreshing',\n",
       " 'aaahhh relaxation',\n",
       " 'aaahhh sigh',\n",
       " 'aaahhh still',\n",
       " 'aaahhh thas',\n",
       " 'aaahhh tired',\n",
       " 'aaahhhh',\n",
       " 'aaahhhh chews',\n",
       " 'aaahhhh diva',\n",
       " 'aaahhhh excited',\n",
       " 'aaahhhh japanese',\n",
       " 'aaahhhh need',\n",
       " 'aaahhhhh',\n",
       " 'aaahhhhh eeeewwwww',\n",
       " 'aaahhhhhhhh',\n",
       " 'aaahhhhhhhh ooooohhhhh',\n",
       " 'aaahing',\n",
       " 'aaahing much',\n",
       " 'aaahp',\n",
       " 'aaahp anyway',\n",
       " 'aaaja',\n",
       " 'aaaja sapnoin',\n",
       " 'aaalso',\n",
       " 'aaalso ich',\n",
       " 'aaalso nicht',\n",
       " 'aaalso weit',\n",
       " 'aaand',\n",
       " 'aaand first',\n",
       " 'aaand gn',\n",
       " 'aaand want',\n",
       " 'aaand works',\n",
       " 'aaannndd',\n",
       " 'aaannndd leads',\n",
       " 'aaannnnd',\n",
       " 'aaannnnd chas',\n",
       " 'aaanyhoo',\n",
       " 'aaanyhoo back',\n",
       " 'aaanyway',\n",
       " 'aaanyway afterwards',\n",
       " 'aaanyway chillin',\n",
       " 'aaanyway found',\n",
       " 'aaanyway shallow',\n",
       " 'aaanyway shut',\n",
       " 'aaappp',\n",
       " 'aaappp party',\n",
       " 'aaare',\n",
       " 'aaare aaaa',\n",
       " 'aaarggghhh',\n",
       " 'aaarggghhh nearly',\n",
       " 'aaargghhhhh',\n",
       " 'aaargghhhhh injury',\n",
       " 'aaargh',\n",
       " 'aaargh anyway',\n",
       " 'aaargh damn',\n",
       " 'aaargh feminine',\n",
       " 'aaargh hier',\n",
       " 'aaargh lol',\n",
       " 'aaargh lolz',\n",
       " 'aaargh naja',\n",
       " 'aaargh practically',\n",
       " 'aaargh sorry',\n",
       " 'aaargh sucked',\n",
       " 'aaargh yesterday',\n",
       " 'aaarmchairgarbageman',\n",
       " 'aaarmchairgarbageman urllink',\n",
       " 'aaarrg',\n",
       " 'aaarrg got',\n",
       " 'aaarrggghhhh',\n",
       " 'aaarrggghhhh curses',\n",
       " 'aaarrgghh',\n",
       " 'aaarrgghh five',\n",
       " 'aaarrh',\n",
       " 'aaarrh leave',\n",
       " 'aaarrrggghh',\n",
       " 'aaarrrggghh pray',\n",
       " 'aaarrrggghhhh',\n",
       " 'aaarrrggghhhh guy',\n",
       " 'aaarrrggghhhhhhhhgggghhhhhh',\n",
       " 'aaarrrggghhhhhhhhgggghhhhhh dropped',\n",
       " 'aaarrrgghhh',\n",
       " 'aaarrrgghhh live',\n",
       " 'aaarrrgghhhhhh',\n",
       " 'aaarrrgghhhhhh hate',\n",
       " 'aaarrrgh',\n",
       " 'aaarrrgh tacky',\n",
       " 'aaarrrghh',\n",
       " 'aaarrrghh sometimes',\n",
       " 'aaarrrrggggghhhhh',\n",
       " 'aaarrrrggggghhhhh realized',\n",
       " 'aaarrrrgggghhh',\n",
       " 'aaarrrrgggghhh ps',\n",
       " 'aaarrrrrr',\n",
       " 'aaarrrrrr bottttttllllllle',\n",
       " 'aaasp',\n",
       " 'aaasp talked',\n",
       " 'aaatch',\n",
       " 'aaatch eeee',\n",
       " 'aaatextbooksearch',\n",
       " 'aaatextbooksearch com',\n",
       " 'aaaugh',\n",
       " 'aaaugh hate',\n",
       " 'aaaw',\n",
       " 'aaaw urllink',\n",
       " 'aaaxccb',\n",
       " 'aaaxccb naihdo',\n",
       " 'aaaye',\n",
       " 'aaaye chuppkee',\n",
       " 'aab',\n",
       " 'aab adopt',\n",
       " 'aab karde',\n",
       " 'aab program',\n",
       " 'aabte',\n",
       " 'aabte normal',\n",
       " 'aac',\n",
       " 'aac encypted',\n",
       " 'aac formating',\n",
       " 'aac new',\n",
       " 'aac really',\n",
       " 'aac think',\n",
       " 'aach',\n",
       " 'aach really',\n",
       " 'aach zum',\n",
       " 'aacharati',\n",
       " 'aacharati sardinian',\n",
       " 'aack',\n",
       " 'aack pulls',\n",
       " 'aactually',\n",
       " 'aactually really',\n",
       " 'aacv',\n",
       " 'aacv ava',\n",
       " 'aacv dr',\n",
       " 'aacv media',\n",
       " 'aacv members',\n",
       " 'aacv special',\n",
       " 'aad',\n",
       " 'aad procedure',\n",
       " 'aadb',\n",
       " 'aadb antianthropophagous',\n",
       " 'aadd',\n",
       " 'aadd hair',\n",
       " 'aadvark',\n",
       " 'aadvark oh',\n",
       " 'aae',\n",
       " 'aae educational',\n",
       " 'aae sometime',\n",
       " 'aaenglish',\n",
       " 'aaenglish html',\n",
       " 'aaf',\n",
       " 'aaf glow',\n",
       " 'aag',\n",
       " 'aag hai',\n",
       " 'aag hoton',\n",
       " 'aag ko',\n",
       " 'aag mein',\n",
       " 'aage',\n",
       " 'aage bjerre',\n",
       " 'aage pohonch',\n",
       " 'aagh',\n",
       " 'aagh nbsp',\n",
       " 'aagirl',\n",
       " 'aagirl peaches',\n",
       " 'aagrh',\n",
       " 'aagrh semantics',\n",
       " 'aah',\n",
       " 'aah atleast',\n",
       " 'aah behold',\n",
       " 'aah cares',\n",
       " 'aah feel',\n",
       " 'aah feels',\n",
       " 'aah gaga',\n",
       " 'aah interesting',\n",
       " 'aah ja',\n",
       " 'aah messiejesse',\n",
       " 'aah nbsp',\n",
       " 'aah nickmac',\n",
       " 'aah nothin',\n",
       " 'aah pencil',\n",
       " 'aah sweet',\n",
       " 'aah trouble',\n",
       " 'aah usual',\n",
       " 'aah well',\n",
       " 'aah whatever',\n",
       " 'aahahaha',\n",
       " 'aahahaha gonna',\n",
       " 'aahahahahahahahahaa',\n",
       " 'aahahahahahahahahaa sick',\n",
       " 'aahed',\n",
       " 'aahed god',\n",
       " 'aaheem',\n",
       " 'aaheem dilah',\n",
       " 'aahh',\n",
       " 'aahh also',\n",
       " 'aahh better',\n",
       " 'aahh call',\n",
       " 'aahh cryin',\n",
       " 'aahh dance',\n",
       " 'aahh emmett',\n",
       " 'aahh gw',\n",
       " 'aahh lol',\n",
       " 'aahh meaning',\n",
       " 'aahh stupid',\n",
       " 'aahhh',\n",
       " 'aahhh anywayz',\n",
       " 'aahhh days',\n",
       " 'aahhh girly',\n",
       " 'aahhh idealised',\n",
       " 'aahhh intending',\n",
       " 'aahhh know',\n",
       " 'aahhh love',\n",
       " 'aahhh okay',\n",
       " 'aahhh soooo',\n",
       " 'aahhh unafraid',\n",
       " 'aahhh wanna',\n",
       " 'aahhhh',\n",
       " 'aahhhh im',\n",
       " 'aahhhh lkjds',\n",
       " 'aahhhh okay',\n",
       " 'aahhhhh',\n",
       " 'aahhhhh saturday',\n",
       " 'aahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh',\n",
       " 'aahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh ahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh',\n",
       " 'aahhnold',\n",
       " 'aahhnold fit',\n",
       " 'aahing',\n",
       " 'aahing firebolt',\n",
       " 'aahs',\n",
       " 'aahs everyone',\n",
       " 'aahs lucky',\n",
       " 'aahs thinks',\n",
       " 'aaih',\n",
       " 'aaih hbub',\n",
       " 'aaih nru',\n",
       " 'aaiiiiiiieeeeeeee',\n",
       " 'aaiiiiiiieeeeeeee one',\n",
       " 'aaj',\n",
       " 'aaj jaldi',\n",
       " 'aaj jumma',\n",
       " 'aaja',\n",
       " 'aaja alternate',\n",
       " 'aaja meri',\n",
       " 'aak',\n",
       " 'aak aan',\n",
       " 'aak far',\n",
       " 'aakalain',\n",
       " 'aakalain na',\n",
       " 'aakalang',\n",
       " 'aakalang kami',\n",
       " 'aakash',\n",
       " 'aakash akshat',\n",
       " 'aakhir',\n",
       " 'aakhir kaun',\n",
       " 'aakhir mein',\n",
       " 'aal',\n",
       " 'aal eliminate',\n",
       " 'aal esseneth',\n",
       " 'aal lost',\n",
       " 'aal rather',\n",
       " 'aalaap',\n",
       " 'aalaap first',\n",
       " 'aalaap nbsp',\n",
       " 'aalaap yesterday',\n",
       " 'aalaga',\n",
       " 'aalaga sayo',\n",
       " 'aalamin',\n",
       " 'aalamin kung',\n",
       " 'aalaska',\n",
       " 'aalaska another',\n",
       " 'aaldering',\n",
       " 'aaldering urllink',\n",
       " 'aalis',\n",
       " 'aalis na',\n",
       " 'aalis tsaka',\n",
       " 'aaliyah',\n",
       " 'aaliyah baby',\n",
       " 'aaliyah back',\n",
       " 'aaliyah said',\n",
       " 'aaliyah weak',\n",
       " 'aall',\n",
       " 'aall time',\n",
       " 'aallowz',\n",
       " 'aallowz hari',\n",
       " 'aalu',\n",
       " 'aalu ke',\n",
       " 'aalu sabji',\n",
       " 'aame',\n",
       " 'aame price',\n",
       " 'aaminin',\n",
       " 'aaminin sana',\n",
       " 'aamir',\n",
       " 'aamir khan',\n",
       " 'aamlitr',\n",
       " 'aamlitr xes',\n",
       " 'aammett',\n",
       " 'aammett sih',\n",
       " 'aan',\n",
       " 'aan aaq',\n",
       " 'aan guuadn',\n",
       " 'aand',\n",
       " 'aand also',\n",
       " 'aand jim',\n",
       " 'aand miss',\n",
       " 'aand things',\n",
       " 'aand wait',\n",
       " 'aane',\n",
       " 'aane laga',\n",
       " 'aane waali',\n",
       " 'aanim',\n",
       " 'aanim ang',\n",
       " 'aankhon',\n",
       " 'aankhon hi',\n",
       " 'aankhon ki',\n",
       " 'aankhon mein',\n",
       " 'aannnnnnnnnnnnndd',\n",
       " 'aannnnnnnnnnnnndd thats',\n",
       " 'aano',\n",
       " 'aano eh',\n",
       " 'aansoon',\n",
       " 'aansoon ko',\n",
       " 'aantay',\n",
       " 'aantay ng',\n",
       " 'aanuhin',\n",
       " 'aanuhin kapatid',\n",
       " 'aanyway',\n",
       " 'aanyway wat',\n",
       " 'aao',\n",
       " 'aao foahu',\n",
       " 'aao lo',\n",
       " 'aap',\n",
       " 'aap baal',\n",
       " 'aap banks',\n",
       " 'aap jee',\n",
       " 'aap log',\n",
       " 'aapl',\n",
       " 'aapl gets',\n",
       " 'aapl got',\n",
       " 'aapl sales',\n",
       " 'aapl stock',\n",
       " 'aapply',\n",
       " 'aapply ng',\n",
       " 'aaq',\n",
       " 'aaq review',\n",
       " 'aar',\n",
       " 'aar njude',\n",
       " 'aaral',\n",
       " 'aaral bweheheheee',\n",
       " 'aaral ka',\n",
       " 'aaral pa',\n",
       " 'aardvark',\n",
       " 'aardvark bile',\n",
       " 'aardvark change',\n",
       " 'aardvark happy',\n",
       " 'aardvark makes',\n",
       " 'aardvark must',\n",
       " 'aardvark snot',\n",
       " 'aardvark soon',\n",
       " 'aardvarks',\n",
       " 'aardvarks ever',\n",
       " 'aardvarks living',\n",
       " 'aardvarks problem',\n",
       " 'aardvarks rear',\n",
       " 'aargh',\n",
       " 'aargh di',\n",
       " 'aargh embarrassing',\n",
       " 'aargh feel',\n",
       " 'aargh frustrating',\n",
       " 'aargh happy',\n",
       " 'aargh hard',\n",
       " 'aargh know',\n",
       " 'aargh people',\n",
       " 'aargh someone',\n",
       " 'aargh still',\n",
       " 'aargh sunday',\n",
       " 'aargh told',\n",
       " 'aargh went',\n",
       " 'aarghhh',\n",
       " 'aarghhh ltr',\n",
       " 'aaron',\n",
       " 'aaron aaron',\n",
       " 'aaron alex',\n",
       " 'aaron already',\n",
       " 'aaron also',\n",
       " 'aaron always',\n",
       " 'aaron amazingly',\n",
       " 'aaron ammon',\n",
       " 'aaron anyways',\n",
       " 'aaron arhhhhhhhhhh',\n",
       " 'aaron ask',\n",
       " 'aaron asked',\n",
       " 'aaron away',\n",
       " 'aaron awwwwwww',\n",
       " 'aaron azim',\n",
       " 'aaron bane',\n",
       " 'aaron basically',\n",
       " 'aaron beano',\n",
       " 'aaron boone',\n",
       " 'aaron break',\n",
       " 'aaron broke',\n",
       " 'aaron brown',\n",
       " 'aaron burr',\n",
       " 'aaron butterknife',\n",
       " 'aaron called',\n",
       " 'aaron came',\n",
       " 'aaron car',\n",
       " 'aaron carter',\n",
       " 'aaron cause',\n",
       " 'aaron celebrated',\n",
       " 'aaron climbed',\n",
       " 'aaron club',\n",
       " 'aaron clue',\n",
       " 'aaron collect',\n",
       " 'aaron coming',\n",
       " 'aaron copeland',\n",
       " 'aaron could',\n",
       " 'aaron crossley',\n",
       " 'aaron de',\n",
       " 'aaron decide',\n",
       " 'aaron decided',\n",
       " 'aaron dick',\n",
       " 'aaron died',\n",
       " 'aaron different',\n",
       " 'aaron digits',\n",
       " 'aaron directly',\n",
       " 'aaron dis',\n",
       " 'aaron done',\n",
       " 'aaron donny',\n",
       " 'aaron douglas',\n",
       " 'aaron dressed',\n",
       " 'aaron drink',\n",
       " 'aaron elandt',\n",
       " 'aaron elise',\n",
       " 'aaron ever',\n",
       " 'aaron filling',\n",
       " 'aaron flashed',\n",
       " 'aaron flop',\n",
       " 'aaron fredrick',\n",
       " 'aaron friend',\n",
       " 'aaron friends',\n",
       " 'aaron fun',\n",
       " 'aaron funny',\n",
       " 'aaron garcia',\n",
       " 'aaron gave',\n",
       " 'aaron gay',\n",
       " 'aaron genius',\n",
       " 'aaron getting',\n",
       " 'aaron gf',\n",
       " 'aaron gilbert',\n",
       " 'aaron glanced',\n",
       " 'aaron go',\n",
       " 'aaron going',\n",
       " 'aaron gone',\n",
       " 'aaron gosports',\n",
       " 'aaron got',\n",
       " 'aaron graduated',\n",
       " 'aaron greg',\n",
       " 'aaron happen',\n",
       " 'aaron harang',\n",
       " 'aaron hard',\n",
       " 'aaron headed',\n",
       " 'aaron heath',\n",
       " 'aaron hit',\n",
       " 'aaron hope',\n",
       " 'aaron hotass',\n",
       " 'aaron hudgens',\n",
       " 'aaron idea',\n",
       " 'aaron inside',\n",
       " 'aaron jail',\n",
       " 'aaron james',\n",
       " 'aaron jessica',\n",
       " 'aaron jessie',\n",
       " 'aaron joined',\n",
       " 'aaron josh',\n",
       " 'aaron journal',\n",
       " 'aaron jumps',\n",
       " 'aaron keep',\n",
       " 'aaron kelly',\n",
       " 'aaron klinefelter',\n",
       " 'aaron know',\n",
       " 'aaron kt',\n",
       " 'aaron kwok',\n",
       " 'aaron lacrosse',\n",
       " 'aaron laid',\n",
       " 'aaron later',\n",
       " 'aaron laughing',\n",
       " 'aaron leaving',\n",
       " 'aaron left',\n",
       " 'aaron lewis',\n",
       " 'aaron like',\n",
       " 'aaron likes',\n",
       " 'aaron long',\n",
       " 'aaron loves',\n",
       " 'aaron luke',\n",
       " 'aaron made',\n",
       " 'aaron mainly',\n",
       " 'aaron manwhore',\n",
       " 'aaron memorial',\n",
       " 'aaron mom',\n",
       " 'aaron much',\n",
       " 'aaron mulled',\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c76d15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=vectorizer.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "533d0f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 3738224)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "221643f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<70000x3738224 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11753157 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73e224e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fc0e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 3738224)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b6f2529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30000x3738224 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3787222 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37207e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa beautiful', 'aa brown', 'aa button', 'aa candle', 'aa charge']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[7:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21f00a",
   "metadata": {},
   "source": [
    "**Counting words in the dataset using loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37f9907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts=dict()\n",
    "\n",
    "for labels in df2.labels.values:\n",
    "    for label in labels:\n",
    "        if label in label_counts:\n",
    "            label_counts[label]+=1\n",
    "        else:\n",
    "            label_counts[label]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b9127bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'male': 53358,\n",
       " '15': 6532,\n",
       " 'Student': 22122,\n",
       " 'Leo': 8230,\n",
       " '33': 2835,\n",
       " 'InvestmentBanking': 244,\n",
       " 'Aquarius': 9050,\n",
       " 'female': 46642,\n",
       " '14': 3540,\n",
       " 'indUnk': 33097,\n",
       " 'Aries': 10637,\n",
       " '25': 8660,\n",
       " 'Capricorn': 8723,\n",
       " '17': 12755,\n",
       " 'Gemini': 9225,\n",
       " '23': 10757,\n",
       " 'Non-Profit': 1326,\n",
       " 'Cancer': 9253,\n",
       " 'Banking': 354,\n",
       " '37': 863,\n",
       " 'Sagittarius': 7366,\n",
       " '26': 8059,\n",
       " '24': 11814,\n",
       " 'Scorpio': 7049,\n",
       " '27': 8007,\n",
       " 'Education': 5553,\n",
       " '45': 906,\n",
       " 'Engineering': 2332,\n",
       " 'Libra': 7250,\n",
       " 'Science': 1090,\n",
       " '34': 2388,\n",
       " '41': 772,\n",
       " 'Communications-Media': 2830,\n",
       " 'BusinessServices': 626,\n",
       " 'Sports-Recreation': 406,\n",
       " 'Virgo': 7134,\n",
       " 'Taurus': 8530,\n",
       " 'Arts': 5031,\n",
       " 'Pisces': 7553,\n",
       " '44': 76,\n",
       " '16': 8406,\n",
       " 'Internet': 2251,\n",
       " 'Museums-Libraries': 308,\n",
       " 'Accounting': 528,\n",
       " '39': 568,\n",
       " '35': 4720,\n",
       " 'Technology': 8484,\n",
       " '36': 3045,\n",
       " 'Law': 360,\n",
       " '46': 914,\n",
       " 'Consulting': 905,\n",
       " 'Automotive': 124,\n",
       " '42': 156,\n",
       " 'Religion': 1081,\n",
       " '13': 1497,\n",
       " 'Fashion': 1898,\n",
       " '38': 801,\n",
       " '43': 505,\n",
       " 'Publishing': 1079,\n",
       " '40': 513,\n",
       " 'Marketing': 726,\n",
       " 'LawEnforcement-Security': 368,\n",
       " 'HumanResources': 209,\n",
       " 'Telecommunications': 165,\n",
       " 'Military': 798,\n",
       " 'Government': 2055,\n",
       " 'Transportation': 745,\n",
       " 'Architecture': 83,\n",
       " 'Advertising': 766,\n",
       " '47': 397,\n",
       " 'Agriculture': 168,\n",
       " 'Biotech': 324,\n",
       " 'RealEstate': 149,\n",
       " 'Manufacturing': 542,\n",
       " '48': 514,\n",
       " 'Construction': 250,\n",
       " 'Chemicals': 305,\n",
       " 'Maritime': 59,\n",
       " 'Tourism': 253,\n",
       " 'Environment': 6}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3a26fd",
   "metadata": {},
   "source": [
    "**MultiLabel Binarizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed3e528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "binarizer=MultiLabelBinarizer(classes=sorted(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c2d5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = binarizer.fit_transform(y_train)\n",
    "y_test = binarizer.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ae570b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 3738224)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec8bd3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 3738224)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e375fa68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 80)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3788d437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 80)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e47167c",
   "metadata": {},
   "source": [
    "<font size=\"5\"><p style=\"color:black\"> <b>3. Design, train, tune and test the best text classifier </p></font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc763858",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Arial; font-weight:bold;font-size:1.3em;color:#00b3e5;\">3.1 Logistic Regression Classifier (LRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5d11a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "model=OneVsRestClassifier(model)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "604fe476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "prediction_LR_train = model.predict(x_train)\n",
    "prediction_LR_test = model.predict(x_test)\n",
    "\n",
    "LRtrain = metrics.accuracy_score(y_train, prediction_LR_train)\n",
    "LRtest = metrics.accuracy_score(y_test, prediction_LR_test)\n",
    "\n",
    "LR_precision_train = precision_score(y_train, prediction_LR_train,average='micro')\n",
    "LR_recall_train = recall_score(y_train, prediction_LR_train,average='micro')\n",
    "\n",
    "LR_precision_test = precision_score(y_test, prediction_LR_test,average='micro')\n",
    "LR_recall_test = recall_score(y_test, prediction_LR_test,average='micro')\n",
    "\n",
    "LR_F1 = 2 * (LR_precision_test * LR_recall_test) / (LR_precision_test + LR_recall_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dd9485",
   "metadata": {},
   "source": [
    "<font size=\"5\"><p style=\"color:black\"> <b>4. Display and explain detail the classification report </p></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f00e5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>accuracy_Train</th>\n",
       "      <th>accuracy_Test</th>\n",
       "      <th>Precision_Train</th>\n",
       "      <th>Precision_Test</th>\n",
       "      <th>Recall_Train</th>\n",
       "      <th>Recall_Test</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.907514</td>\n",
       "      <td>0.1073</td>\n",
       "      <td>0.996253</td>\n",
       "      <td>0.710154</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.359492</td>\n",
       "      <td>0.477344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Method  accuracy_Train  accuracy_Test  Precision_Train  \\\n",
       "0  Logistic Regression        0.907514         0.1073         0.996253   \n",
       "\n",
       "   Precision_Test  Recall_Train  Recall_Test  F1-Score  \n",
       "0        0.710154         0.944     0.359492  0.477344  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDf = pd.DataFrame({'Method':['Logistic Regression'], 'accuracy_Train': [LRtrain],'accuracy_Test': [LRtest],'Precision_Train': [LR_precision_train],'Precision_Test':[LR_precision_test],'Recall_Train':[LR_recall_train],'Recall_Test':[LR_recall_test], 'F1-Score':[LR_F1]})\n",
    "resultsDf = resultsDf[['Method', 'accuracy_Train','accuracy_Test','Precision_Train','Precision_Test','Recall_Train','Recall_Test','F1-Score']]\n",
    "resultsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790e244",
   "metadata": {},
   "source": [
    "<font size=\"5\"><p style=\"color:black\"> <b>5. Print the true vs predicted labels for any 5 entries from the dataset. </p></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f633a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def print_predicted(y_predicted=prediction_LR_test, y_test = y_test , n = 5):\n",
    "    j = []\n",
    "    for i in range(n):\n",
    "        j.append(random.randint(0, len(y_test)))\n",
    "    print(j)\n",
    "                 \n",
    "    for k in j:\n",
    "        print('ORIGINAL:',binarizer.inverse_transform(y_test)[k])\n",
    "        print('PREDICTED:',binarizer.inverse_transform(y_predicted)[k])\n",
    "        print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b315f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11272, 21730, 19155, 24704, 9145]\n",
      "ORIGINAL: ('16', 'Leo', 'Student', 'male')\n",
      "PREDICTED: ('male',)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "ORIGINAL: ('23', 'Sagittarius', 'indUnk', 'male')\n",
      "PREDICTED: ('female',)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "ORIGINAL: ('34', 'Aquarius', 'Education', 'male')\n",
      "PREDICTED: ('34', 'Aquarius', 'Education', 'male')\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "ORIGINAL: ('27', 'Aquarius', 'Technology', 'female')\n",
      "PREDICTED: ('27', 'Aquarius', 'female')\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "ORIGINAL: ('13', 'Aries', 'female', 'indUnk')\n",
      "PREDICTED: ('female', 'indUnk')\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n"
     ]
    }
   ],
   "source": [
    "print_predicted(y_predicted=prediction_LR_test,y_test=y_test, n= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f254881d",
   "metadata": {},
   "source": [
    "### The above Logistic Regression classification model gave 10.73% accuracy, 71% Precision, 35% Recall on validation data. Though the accuracy is low, the model prediction is quite good, and can be improved based on data. This model can be used in production and can be implemented to an extent due to the predictability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
